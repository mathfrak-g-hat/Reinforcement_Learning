{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7db65ac9-4942-422c-b2ad-4d6c3af80373",
   "metadata": {},
   "source": [
    "# Simplified DDPG in PyTorch Lightning\n",
    "### AJ Zerouali, 2023/06/21\n",
    "\n",
    "Goals of this notebook:\n",
    "* Modify pl-bolts' implementation of SAC to get a simplified DDPG.\n",
    "* Reduce the number of imports for the *nn.LightningModule* implementation (e.g. get rid of the agent class, as well as the nets).\n",
    "* Replace the algo's *env* attribute by *test_env* passed as a parameter.\n",
    "* Wrap all this in a general agent class that has a *train()* method that creates a *Trainer* attribute. Instead of having the agent as an attribute of the *LightningModule*, make an agent that has the *LightningModule* as an attribute. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19125f1-c898-4e93-a75f-ff804f73fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch import Tensor, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5028a7a2-0114-41f6-a3eb-1d2c5f03301f",
   "metadata": {},
   "source": [
    "Temporary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f5843b1-a84c-404e-adfd-6c4b952385fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
     ]
    }
   ],
   "source": [
    "from RL_lightning_bolts_template.pl_bolts_replay_buffers import Experience, ExperienceSourceDataset, MultiStepBuffer\n",
    "from RL_lightning_bolts_template.pl_bolts_agents import SoftActorCriticAgent\n",
    "from RL_lightning_bolts_template.pl_bolts_nets import MLP, ContinuousMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4ec41e-2d5e-4295-b632-131c285396c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1) Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e0444f-9921-4e4b-bfa2-acbe8201bb69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bd594d-01fb-479f-9d1e-4740528cfe52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b88946-023c-47c5-8e6e-fc0a5cdbe6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f8fb707-832d-4e33-98a9-f083cc73e8fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2) Neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eab6117-91d4-4d68-a873-ddef6ba706d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import FloatTensor, Tensor, nn\n",
    "from torch.distributions import Categorical, Normal, MultivariateNormal\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4d5761-edf8-40eb-b8c2-27330b85c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Source:\n",
    "\n",
    "https://github.com/Lightning-Universe/lightning-bolts/blob/0.5.0/pl_bolts/models/rl/common/distributions.py\n",
    "'''\n",
    "class TanhMultivariateNormal(torch.distributions.MultivariateNormal):\n",
    "    \"\"\"The distribution of X is an affine of tanh applied on a normal distribution.\n",
    "    X = action_scale * tanh(Z) + action_bias\n",
    "    Z ~ Normal(mean, variance)\n",
    "    \n",
    "    AJ Zerouali, 23/06/21: They forgot about the devices\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, action_bias, action_scale, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.action_bias = action_bias\n",
    "        self.action_scale = action_scale\n",
    "\n",
    "    def rsample_with_z(self, sample_shape=torch.Size()):\n",
    "        \"\"\"Samples X using reparametrization trick with the intermediate variable Z.\n",
    "        Returns:\n",
    "            Sampled X and Z\n",
    "        \"\"\"\n",
    "        z = super().rsample()\n",
    "        '''\n",
    "        # DEBUG\n",
    "        print(f\"z.device = {z.device}\")\n",
    "        print(f\"type(z) = {type(z)}\")\n",
    "        print(f\"self.action_scale.device = {self.action_scale.device}\")\n",
    "        print(f\"self.action_bias.device = {self.action_bias.device}\")\n",
    "        #print(f\"next(self.parameters()).is_cuda = {next(self.parameters()).is_cuda}\")\n",
    "        '''\n",
    "        \n",
    "        action_scale = torch.Tensor(self.action_scale).to(z.device)\n",
    "        action_bias = torch.Tensor(self.action_bias).to(z.device)\n",
    "        \n",
    "        output = (action_scale * torch.tanh(z) + action_bias, z)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def log_prob_with_z(self, value, z):\n",
    "        \"\"\"Computes the log probability of a sampled X.\n",
    "        Refer to the original paper of SAC for more details in equation (20), (21)\n",
    "        Args:\n",
    "            value: the value of X\n",
    "            z: the value of Z\n",
    "        Returns:\n",
    "            Log probability of the sample\n",
    "        \"\"\"\n",
    "        action_scale = torch.Tensor(self.action_scale).to(z.device)\n",
    "        action_bias = torch.Tensor(self.action_bias).to(z.device)\n",
    "        \n",
    "        value = (value - action_bias) / action_scale\n",
    "        z_logprob = super().log_prob(z)\n",
    "        correction = torch.log(action_scale * (1 - value ** 2) + 1e-7).sum(1)\n",
    "        return z_logprob - correction\n",
    "\n",
    "    def rsample_and_log_prob(self, sample_shape=torch.Size()):\n",
    "        \"\"\"Samples X and computes the log probability of the sample.\n",
    "        Returns:\n",
    "            Sampled X and log probability\n",
    "        \"\"\"\n",
    "        \n",
    "        z = super().rsample()\n",
    "        z_logprob = super().log_prob(z)\n",
    "        value = torch.tanh(z)\n",
    "        \n",
    "        action_scale = torch.Tensor(self.action_scale).to(z.device)\n",
    "        action_bias = torch.Tensor(self.action_bias).to(z.device)        \n",
    "        \n",
    "        correction = torch.log(action_scale * (1 - value ** 2) + 1e-7).sum(1)\n",
    "        return action_scale * value + action_bias, z_logprob - correction\n",
    "\n",
    "    def rsample(self, sample_shape=torch.Size()):\n",
    "        fz, z = self.rsample_with_z(sample_shape)\n",
    "        return fz\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        \n",
    "        action_scale = torch.Tensor(self.action_scale).to(value.device)\n",
    "        action_bias = torch.Tensor(self.action_bias).to(value.device)\n",
    "        \n",
    "        value = (value - action_bias) / action_scale\n",
    "        z = torch.log(1 + value) / 2 - torch.log(1 - value) / 2\n",
    "        return self.log_prob_with_z(value, z)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6db473-3c82-4165-964c-e026e89eae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "'''\n",
    "Source:\n",
    " \n",
    "https://github.com/Lightning-Universe/lightning-bolts/blob/0.5.0/pl_bolts/models/rl/common/networks.py\n",
    "'''\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Simple MLP network.\"\"\"\n",
    "\n",
    "    def __init__(self, input_shape: Tuple[int], n_actions: int, hidden_size: int = 128):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_shape: observation shape of the environment\n",
    "            n_actions: number of discrete actions available in the environment\n",
    "            hidden_size: size of hidden layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_actions),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_x):\n",
    "        \"\"\"Forward pass through network.\n",
    "        Args:\n",
    "            x: input to network\n",
    "        Returns:\n",
    "            output of network\n",
    "        \"\"\"\n",
    "        return self.net(input_x.float())\n",
    "\n",
    "class ContinuousMLP(nn.Module):\n",
    "    \"\"\"MLP network that outputs continuous value via Gaussian distribution.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: Tuple[int],\n",
    "        n_actions: int,\n",
    "        hidden_size: int = 128,\n",
    "        action_bias: int = 0,\n",
    "        action_scale: int = 1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_shape: observation shape of the environment\n",
    "            n_actions: dimension of actions in the environment\n",
    "            hidden_size: size of hidden layers\n",
    "            action_bias: the center of the action space\n",
    "            action_scale: the scale of the action space\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.action_bias = action_bias\n",
    "        self.action_scale = action_scale\n",
    "\n",
    "        self.shared_net = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], hidden_size), nn.ReLU(), nn.Linear(hidden_size, hidden_size), nn.ReLU()\n",
    "        )\n",
    "        self.mean_layer = nn.Linear(hidden_size, n_actions)\n",
    "        self.logstd_layer = nn.Linear(hidden_size, n_actions)\n",
    "\n",
    "    def forward(self, x: FloatTensor) -> TanhMultivariateNormal:\n",
    "        \"\"\"Forward pass through network. Calculates the action distribution.\n",
    "        Args:\n",
    "            x: input to network\n",
    "        Returns:\n",
    "            action distribution\n",
    "        \"\"\"\n",
    "        # DEBUG\n",
    "        #print(f\"x.device = {x.device}\")\n",
    "        #print(f\"next(self.parameters()).is_cuda = {next(self.parameters()).is_cuda}\")\n",
    "        \n",
    "        x = self.shared_net(x.float())\n",
    "        batch_mean = self.mean_layer(x)\n",
    "        logstd = torch.clamp(self.logstd_layer(x), -20, 2)\n",
    "        batch_scale_tril = torch.diag_embed(torch.exp(logstd))\n",
    "        output = TanhMultivariateNormal(action_bias=self.action_bias, \n",
    "                                        action_scale=self.action_scale, \n",
    "                                        loc=batch_mean, \n",
    "                                        scale_tril=batch_scale_tril,)\n",
    "        return output\n",
    "\n",
    "    def get_action(self, x: FloatTensor) -> Tensor:\n",
    "        \"\"\"Get the action greedily (without sampling)\n",
    "        Args:\n",
    "            x: input to network\n",
    "        Returns:\n",
    "            mean action\n",
    "        \"\"\"\n",
    "        x = self.shared_net(x.float())\n",
    "        batch_mean = self.mean_layer(x)\n",
    "        return self.action_scale * torch.tanh(batch_mean) + self.action_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0488f9-e94b-41a8-8045-dfe253851dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1fef31-cc04-4488-9061-235187a10d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7a6f966-913b-4754-b228-f616be139427",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3) Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bcc8730-96db-46bd-8519-0b7b6a472c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baa52cce-a2e0-426b-ad18-fc10b5718a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPGS(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env, # Initially a str\n",
    "        eps_start: float = 1.0,\n",
    "        eps_end: float = 0.02,\n",
    "        eps_last_frame: int = 150000,\n",
    "        sync_rate: int = 1,\n",
    "        gamma: float = 0.99,\n",
    "        policy_learning_rate: float = 3e-4,\n",
    "        q_learning_rate: float = 3e-4,\n",
    "        target_alpha: float = 5e-3,\n",
    "        batch_size: int = 128,\n",
    "        replay_size: int = 1000000,\n",
    "        warm_start_size: int = 10000,\n",
    "        avg_reward_len: int = 100,\n",
    "        min_episode_reward: int = -21,\n",
    "        seed: int = 123,\n",
    "        batches_per_epoch: int = 10000,\n",
    "        n_steps: int = 1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        ### NOTE: I dislike this\n",
    "        # Training environment\n",
    "        self.env = env\n",
    "        #self.env = gym.make(env)\n",
    "        #self.test_env = gym.make(env)\n",
    "\n",
    "        self.obs_shape = self.env.observation_space.shape\n",
    "        self.n_actions = self.env.action_space.shape[0]\n",
    "\n",
    "        # Model Attributes\n",
    "        self.buffer = None\n",
    "        self.dataset = None\n",
    "\n",
    "        self.policy = None\n",
    "        self.q_net = None\n",
    "        self.target_q_net = None\n",
    "        self.build_networks()\n",
    "\n",
    "        '''\n",
    "        ### IMPORTANT: The policy net is the agent's net.\n",
    "        self.agent = SoftActorCriticAgent(self.policy)\n",
    "        '''\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Metrics\n",
    "        self.total_episode_steps = [0]\n",
    "        self.total_rewards = [0]\n",
    "        self.done_episodes = 0\n",
    "        self.total_steps = 0\n",
    "\n",
    "        # Average Rewards\n",
    "        self.avg_reward_len = avg_reward_len\n",
    "\n",
    "        for _ in range(avg_reward_len):\n",
    "            self.total_rewards.append(torch.tensor(min_episode_reward, device=self.device))\n",
    "\n",
    "        self.avg_rewards = float(np.mean(self.total_rewards[-self.avg_reward_len :]))\n",
    "\n",
    "        ### NOTE: Change this\n",
    "        # I don't think this is needed\n",
    "        #self.state, _ = self.env.reset()\n",
    "\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "    '''\n",
    "        AJZerouali\n",
    "    '''\n",
    "    # This method is originally from SoftActorCriticAgent(Agent)\n",
    "    def get_action(self, states: Tensor, device: str) -> List[float]:\n",
    "        \"\"\"Get the action greedily (without sampling)\n",
    "        Args:\n",
    "            states: current state of the environment\n",
    "            device: the device used for the current batch\n",
    "        Returns:\n",
    "            action defined by policy\n",
    "        \n",
    "        if not isinstance(states, list):\n",
    "            states = [states]\n",
    "\n",
    "        if not isinstance(states, Tensor):\n",
    "            states = torch.tensor(states, device=device)\n",
    "\n",
    "        # CRUCIAL: Replace self.net by the appropriate network\n",
    "        # The get_action() method here is that of ContinuousMLP\n",
    "        actions = [self.net.get_action(states).cpu().numpy()]\n",
    "\n",
    "        return actions\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    # This is originally SoftActorCriticAgent.__call__()\n",
    "    def policy_eval(self, states: Tensor, device: str) -> List[float]:\n",
    "        \"\"\"Takes in the current state and returns the action based on the agents policy.\n",
    "        Args:\n",
    "            states: current state of the environment\n",
    "            device: the device used for the current batch\n",
    "        Returns:\n",
    "            action defined by policy\n",
    "        \"\"\"\n",
    "        if not isinstance(states, list):\n",
    "            states = [states]\n",
    "\n",
    "        if not isinstance(states, Tensor):\n",
    "            states = torch.tensor(states, device=device)\n",
    "\n",
    "        # CRUCIAL: Replace self.net by the appropriate network\n",
    "        #dist = self.net(states)\n",
    "        #policy_out = self.policy(states)\n",
    "        actions_ = self.policy(states)\n",
    "        actions = actions_.cpu().detach().numpy()\n",
    "        \n",
    "        # IMPORTANT: Change this\n",
    "        #actions = [a for a in dist.sample().cpu().numpy()]\n",
    "        #actions = [a for a in policy_out.cpu().numpy()]\n",
    "\n",
    "        return actions\n",
    "    \n",
    "    '''\n",
    "        PL-BOLTS\n",
    "    '''\n",
    "    def run_n_episodes(self, env, n_epsiodes: int = 1) -> List[int]:\n",
    "        \"\"\"Carries out N episodes of the environment with the current agent without exploration.\n",
    "\n",
    "        Args:\n",
    "            env: environment to use, either train environment or test environment\n",
    "            n_epsiodes: number of episodes to run\n",
    "        \"\"\"\n",
    "        total_rewards = []\n",
    "\n",
    "        for _ in range(n_epsiodes):\n",
    "            episode_state, _ = env.reset()\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "\n",
    "            while not done:\n",
    "                #### CRUCIAL: Replace self.agent\n",
    "                #action = self.agent.get_action(episode_state, self.device)\n",
    "                #action = self.get_action(self.state, self.device)\n",
    "                action = self.policy_eval(self.state, self.device)\n",
    "                \n",
    "                # gym v0.26.2+: step() returns (observation, reward, terminated, truncated, info)\n",
    "                next_state, reward, done, _, _ = env.step(action[0])\n",
    "                episode_state = next_state\n",
    "                episode_reward += reward\n",
    "\n",
    "            total_rewards.append(episode_reward)\n",
    "\n",
    "        return total_rewards\n",
    "\n",
    "    def populate(self, warm_start: int) -> None:\n",
    "        \"\"\"Populates the buffer with initial experience.\"\"\"\n",
    "        if warm_start > 0:\n",
    "            self.state, _ = self.env.reset()\n",
    "\n",
    "            for _ in range(warm_start):\n",
    "                #### CRUCIAL: Replace self.agent\n",
    "                #action = self.agent(self.state, self.device)\n",
    "                action = self.policy_eval(self.state, self.device)\n",
    "                \n",
    "                next_state, reward, done, _, _ = self.env.step(action[0])\n",
    "                \n",
    "                # NOTE: Change this shit\n",
    "                exp = Experience(state=self.state, \n",
    "                                 action=action[0], \n",
    "                                 reward=reward, \n",
    "                                 done=done, \n",
    "                                 new_state=next_state)\n",
    "                \n",
    "                self.buffer.append(exp)\n",
    "                self.state = next_state\n",
    "\n",
    "                if done:\n",
    "                    self.state, _ = self.env.reset()\n",
    "\n",
    "    def build_networks(self) -> None:\n",
    "        \"\"\"Initializes the DDPG policy and q network with target\"\"\"\n",
    "        '''\n",
    "        # NOTE: Remove these\n",
    "        action_bias = torch.from_numpy((self.env.action_space.high + self.env.action_space.low) / 2)\n",
    "        action_scale = torch.from_numpy((self.env.action_space.high - self.env.action_space.low) / 2)\n",
    "        \n",
    "        # IMPORTANT: This has to change. The policy is deterministic\n",
    "        self.policy = ContinuousMLP(self.obs_shape, self.n_actions, \n",
    "                                    action_bias=action_bias, \n",
    "                                    action_scale=action_scale)\n",
    "        '''\n",
    "        self.policy = MLP(self.obs_shape, self.n_actions)\n",
    "\n",
    "        concat_shape = [self.obs_shape[0] + self.n_actions]\n",
    "        self.q_net = MLP(concat_shape, 1)\n",
    "        self.target_q_net = MLP(concat_shape, 1)\n",
    "        self.target_q_net.load_state_dict(self.q_net.state_dict())\n",
    "\n",
    "    def soft_update_target(self):\n",
    "        \"\"\"Update the weights in target network using a weighted sum.\n",
    "\n",
    "        w_target := (1-a) * w_target + a * w_q\n",
    "\n",
    "        Args:\n",
    "            q_net: the critic (q) network\n",
    "            target_net: the target (q) network\n",
    "        \"\"\"\n",
    "        ### IMPORTANT: Change this call too. This is incomprehensible...\n",
    "        for q_param, target_param in zip(self.q_net.parameters(), self.target_q_net.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                (1.0 - self.hparams.target_alpha) * target_param.data + self.hparams.target_alpha * q_param\n",
    "            )\n",
    "\n",
    "    def forward(self, state: Tensor) -> Tensor:\n",
    "        \"\"\"Passes in a state x through the network and gets the q_values of each action as an output.\n",
    "\n",
    "        Args:\n",
    "            state: environment state\n",
    "\n",
    "        Returns:\n",
    "            q values\n",
    "        \"\"\"\n",
    "        # IMPORTANT: no sample() here for DDPG\n",
    "        #output = self.policy(x).sample()\n",
    "        output = self.policy(state)\n",
    "        return output\n",
    "\n",
    "    def train_batch(\n",
    "        self,\n",
    "    ) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
    "        \"\"\"Contains the logic for generating a new batch of data to be passed to the DataLoader.\n",
    "\n",
    "        Returns:\n",
    "            yields a Experience tuple containing the state, action, reward, done and next_state.\n",
    "        \"\"\"\n",
    "        episode_reward = 0\n",
    "        episode_steps = 0\n",
    "\n",
    "        while True:\n",
    "            self.total_steps += 1\n",
    "            \n",
    "            #### CRUCIAL: Replace self.agent\n",
    "            #action = self.agent(self.state, self.device)\n",
    "            action = self.policy_eval(self.state, self.device)\n",
    "\n",
    "            next_state, r, is_done, _, _ = self.env.step(action[0])\n",
    "\n",
    "            episode_reward += r\n",
    "            episode_steps += 1\n",
    "\n",
    "            # IMPORTANT: Please change these names before I lose it\n",
    "            exp = Experience(state=self.state, \n",
    "                             action=action[0], \n",
    "                             reward=r, \n",
    "                             done=is_done, \n",
    "                             new_state=next_state)\n",
    "\n",
    "            self.buffer.append(exp)\n",
    "            self.state = next_state\n",
    "\n",
    "            if is_done:\n",
    "                self.done_episodes += 1\n",
    "                self.total_rewards.append(episode_reward)\n",
    "                self.total_episode_steps.append(episode_steps)\n",
    "                self.avg_rewards = float(np.mean(self.total_rewards[-self.avg_reward_len :]))\n",
    "                self.state, _ = self.env.reset()\n",
    "                episode_steps = 0\n",
    "                episode_reward = 0\n",
    "\n",
    "            states, actions, rewards, dones, new_states = self.buffer.sample(self.hparams.batch_size)\n",
    "\n",
    "            for idx, _ in enumerate(dones):\n",
    "                yield states[idx], actions[idx], rewards[idx], dones[idx], new_states[idx]\n",
    "\n",
    "            # Simulates epochs\n",
    "            if self.total_steps % self.hparams.batches_per_epoch == 0:\n",
    "                break\n",
    "\n",
    "    def loss(self, batch: Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "        \"\"\"Calculates the loss for SAC which contains a total of 3 losses.\n",
    "\n",
    "        Args:\n",
    "            batch: a batch of states, actions, rewards, dones, and next states\n",
    "        \"\"\"\n",
    "        states, actions, rewards, dones, next_states = batch\n",
    "        rewards = rewards.unsqueeze(-1)\n",
    "        dones = dones.float().unsqueeze(-1)\n",
    "\n",
    "        # actor\n",
    "        '''\n",
    "        ### IMPORTANT: Has to be changed\n",
    "        dist = self.policy(states)\n",
    "        new_actions, new_logprobs = dist.rsample_and_log_prob()\n",
    "        new_logprobs = new_logprobs.unsqueeze(-1)\n",
    "        '''\n",
    "        new_actions = self.policy(states)\n",
    "        '''\n",
    "        new_states_actions = torch.cat((states, new_actions), 1)\n",
    "        new_q1_values = self.q1(new_states_actions)\n",
    "        new_q2_values = self.q2(new_states_actions)\n",
    "        new_qmin_values = torch.min(new_q1_values, new_q2_values)\n",
    "        '''\n",
    "        new_states_actions = torch.cat((states, new_actions), 1)\n",
    "        new_q_values = self.q_net(new_states_actions)\n",
    "\n",
    "        '''\n",
    "        policy_loss = (new_logprobs - new_qmin_values).mean()\n",
    "        '''\n",
    "        policy_loss = -new_q_values.mean()\n",
    "\n",
    "        # critic\n",
    "        ## Everything's fucking backwards in this implementation...\n",
    "        states_actions = torch.cat((states, actions), 1)\n",
    "        '''\n",
    "        q1_values = self.q1(states_actions)\n",
    "        q2_values = self.q2(states_actions)\n",
    "        '''\n",
    "        q_values = self.q_net(states_actions)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            '''\n",
    "            next_dist = self.policy(next_states)\n",
    "            new_next_actions, new_next_logprobs = next_dist.rsample_and_log_prob()\n",
    "            new_next_logprobs = new_next_logprobs.unsqueeze(-1)\n",
    "\n",
    "            new_next_states_actions = torch.cat((next_states, new_next_actions), 1)\n",
    "            next_q1_values = self.target_q1(new_next_states_actions)\n",
    "            next_q2_values = self.target_q2(new_next_states_actions)\n",
    "            next_qmin_values = torch.min(next_q1_values, next_q2_values) - new_next_logprobs\n",
    "            target_values = rewards + (1.0 - dones) * self.hparams.gamma * next_qmin_values\n",
    "            '''\n",
    "            new_next_actions = self.policy(next_states)\n",
    "            new_next_states_actions = torch.cat((next_states, new_next_actions), 1)\n",
    "            next_q_values = self.target_q_net(new_next_states_actions)\n",
    "            \n",
    "            target_q_values = rewards + (1.0 - dones) * self.hparams.gamma * next_q_values\n",
    "            \n",
    "        '''\n",
    "        q1_loss = F.mse_loss(q1_values, target_values)\n",
    "        q2_loss = F.mse_loss(q2_values, target_values)\n",
    "        \n",
    "        return policy_loss, q1_loss, q2_loss\n",
    "        '''\n",
    "        critic_loss= F.mse_loss(q_values, target_q_values)\n",
    "        \n",
    "        return policy_loss, critic_loss\n",
    "\n",
    "\n",
    "    def training_step(self, batch: Tuple[Tensor, Tensor], _):\n",
    "        \"\"\"Carries out a single step through the environment to update the replay buffer. Then calculates loss\n",
    "        based on the minibatch recieved.\n",
    "\n",
    "        Args:\n",
    "            batch: current mini batch of replay data\n",
    "            _: batch number, not used\n",
    "        \"\"\"\n",
    "        # IMPORTANT: This changes\n",
    "        #policy_optim, q1_optim, q2_optim = self.optimizers()\n",
    "        #policy_loss, q1_loss, q2_loss = self.loss(batch)\n",
    "        policy_optim, critic_optim = self.optimizers()\n",
    "        policy_loss, critic_loss = self.loss(batch)\n",
    "\n",
    "        policy_optim.zero_grad()\n",
    "        self.manual_backward(policy_loss)\n",
    "        policy_optim.step()\n",
    "        \n",
    "        '''\n",
    "        q1_optim.zero_grad()\n",
    "        self.manual_backward(q1_loss)\n",
    "        q1_optim.step()\n",
    "        \n",
    "        q2_optim.zero_grad()\n",
    "        self.manual_backward(q2_loss)\n",
    "        q2_optim.step()\n",
    "        '''\n",
    "        critic_optim.zero_grad()\n",
    "        self.manual_backward(critic_loss)\n",
    "        critic_optim.step()\n",
    "\n",
    "        # Soft update of target network\n",
    "        if self.global_step % self.hparams.sync_rate == 0:\n",
    "            self.soft_update_target()\n",
    "\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"total_reward\": self.total_rewards[-1],\n",
    "                \"avg_reward\": self.avg_rewards,\n",
    "                \"policy_loss\": policy_loss,\n",
    "                \"critic_loss\": critic_loss,\n",
    "                \"episodes\": self.done_episodes,\n",
    "                \"episode_steps\": self.total_episode_steps[-1],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    ## Question: What is this?\n",
    "    def test_step(self, *args, **kwargs) -> Dict[str, Tensor]:\n",
    "        \"\"\"Evaluate the agent for 10 episodes.\"\"\"\n",
    "        test_reward = self.run_n_episodes(self.test_env, 1)\n",
    "        avg_reward = sum(test_reward) / len(test_reward)\n",
    "        return {\"test_reward\": avg_reward}\n",
    "\n",
    "    def test_epoch_end(self, outputs) -> Dict[str, Tensor]:\n",
    "        \"\"\"Log the avg of the test results.\"\"\"\n",
    "        rewards = [x[\"test_reward\"] for x in outputs]\n",
    "        avg_reward = sum(rewards) / len(rewards)\n",
    "        self.log(\"avg_test_reward\", avg_reward)\n",
    "        return {\"avg_test_reward\": avg_reward}\n",
    "\n",
    "    '''\n",
    "        NOTE: The replay buffer changes\n",
    "    '''\n",
    "    def _dataloader(self) -> DataLoader:\n",
    "        \"\"\"Initialize the Replay Buffer dataset used for retrieving experiences.\"\"\"\n",
    "        self.buffer = MultiStepBuffer(self.hparams.replay_size, self.hparams.n_steps)\n",
    "        self.populate(self.hparams.warm_start_size)\n",
    "\n",
    "        self.dataset = ExperienceSourceDataset(self.train_batch)\n",
    "        return DataLoader(dataset=self.dataset, batch_size=self.hparams.batch_size)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Get train loader.\"\"\"\n",
    "        return self._dataloader()\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Get test loader.\"\"\"\n",
    "        return self._dataloader()\n",
    "\n",
    "    def configure_optimizers(self) -> Tuple[Optimizer]:\n",
    "        \"\"\"Initialize Adam optimizer.\"\"\"\n",
    "        '''\n",
    "        policy_optim = optim.Adam(self.policy.parameters(), self.hparams.policy_learning_rate)\n",
    "        q1_optim = optim.Adam(self.q1.parameters(), self.hparams.q_learning_rate)\n",
    "        q2_optim = optim.Adam(self.q2.parameters(), self.hparams.q_learning_rate)\n",
    "        return policy_optim, q1_optim, q2_optim\n",
    "        '''\n",
    "        policy_optim = optim.Adam(self.policy.parameters(), self.hparams.policy_learning_rate)\n",
    "        critic_optim = optim.Adam(self.q_net.parameters(), self.hparams.q_learning_rate)\n",
    "        return policy_optim, critic_optim\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(\n",
    "        arg_parser: argparse.ArgumentParser,\n",
    "    ) -> argparse.ArgumentParser:\n",
    "        \"\"\"Adds arguments for DQN model.\n",
    "\n",
    "        Note:\n",
    "            These params are fine tuned for Pong env.\n",
    "\n",
    "        Args:\n",
    "            arg_parser: parent parser\n",
    "        \"\"\"\n",
    "        arg_parser.add_argument(\n",
    "            \"--sync_rate\",\n",
    "            type=int,\n",
    "            default=1,\n",
    "            help=\"how many frames do we update the target network\",\n",
    "        )\n",
    "        arg_parser.add_argument(\n",
    "            \"--replay_size\",\n",
    "            type=int,\n",
    "            default=1000000,\n",
    "            help=\"capacity of the replay buffer\",\n",
    "        )\n",
    "        arg_parser.add_argument(\n",
    "            \"--warm_start_size\",\n",
    "            type=int,\n",
    "            default=10000,\n",
    "            help=\"how many samples do we use to fill our buffer at the start of training\",\n",
    "        )\n",
    "        arg_parser.add_argument(\"--batches_per_epoch\", type=int, default=10000, help=\"number of batches in an epoch\")\n",
    "        arg_parser.add_argument(\"--batch_size\", type=int, default=128, help=\"size of the batches\")\n",
    "        arg_parser.add_argument(\"--policy_lr\", type=float, default=3e-4, help=\"policy learning rate\")\n",
    "        arg_parser.add_argument(\"--q_lr\", type=float, default=3e-4, help=\"q learning rate\")\n",
    "        arg_parser.add_argument(\"--env\", type=str, required=True, help=\"gym environment tag\")\n",
    "        arg_parser.add_argument(\"--gamma\", type=float, default=0.99, help=\"discount factor\")\n",
    "\n",
    "        arg_parser.add_argument(\n",
    "            \"--avg_reward_len\",\n",
    "            type=int,\n",
    "            default=100,\n",
    "            help=\"how many episodes to include in avg reward\",\n",
    "        )\n",
    "        arg_parser.add_argument(\n",
    "            \"--n_steps\",\n",
    "            type=int,\n",
    "            default=1,\n",
    "            help=\"how many frames do we update the target network\",\n",
    "        )\n",
    "\n",
    "        return arg_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b553b-a6ad-4153-ac50-8316de7b74e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9cb268e-62f2-4d69-99fe-2ae29020b20d",
   "metadata": {},
   "source": [
    "# Testing the Algo (Version 2 - 2306272150)\n",
    "\n",
    "I modifed the hard-coded MLP sizes in pl_bolts_nets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1413bcc3-a91d-4c8f-ad89-2609a9f2b7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch import Tensor, optim, FloatTensor, Tensor, nn\n",
    "from torch.distributions import Categorical, Normal, MultivariateNormal\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "886ed07a-a12f-45f0-ae10-e27b202b11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RL_lightning_bolts_template.pl_ddpgs import DDPGS\n",
    "from RL_lightning_bolts_template.pl_bolts_nets import TanhMultivariateNormal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56331cb-3c20-4383-8a40-6dc07a2e9563",
   "metadata": {},
   "source": [
    "## A) Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0005a7d-efd9-4352-bc74-5a49e9c832bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Critic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6e758d-3cbd-45d0-a24c-88b3a70b2b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Simple MLP network.\"\"\"\n",
    "\n",
    "    def __init__(self, input_shape: Tuple[int], n_actions: int, hidden_size: int = 128):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_shape: observation shape of the environment\n",
    "            n_actions: number of discrete actions available in the environment\n",
    "            hidden_size: size of hidden layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        '''\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_actions),\n",
    "        )\n",
    "        '''\n",
    "        # AJZ, 23/06/25\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(400, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(300, n_actions),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_x):\n",
    "        \"\"\"Forward pass through network.\n",
    "        Args:\n",
    "            x: input to network\n",
    "        Returns:\n",
    "            output of network\n",
    "        \"\"\"\n",
    "        return self.net(input_x.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719fc527-fb40-4e97-8db2-e6ffd5f32dcd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Actor net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db9e46d-492d-4192-a972-d45054d31e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousMLP(nn.Module):\n",
    "    \"\"\"MLP network that outputs continuous value via Gaussian distribution.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: Tuple[int],\n",
    "        n_actions: int,\n",
    "        hidden_size: int = 128,\n",
    "        action_bias: int = 0,\n",
    "        action_scale: int = 1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_shape: observation shape of the environment\n",
    "            n_actions: dimension of actions in the environment\n",
    "            hidden_size: size of hidden layers\n",
    "            action_bias: the center of the action space\n",
    "            action_scale: the scale of the action space\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.action_bias = action_bias\n",
    "        self.action_scale = action_scale\n",
    "        '''\n",
    "        self.shared_net = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], hidden_size), nn.ReLU(), nn.Linear(hidden_size, hidden_size), nn.ReLU()\n",
    "        )\n",
    "        self.mean_layer = nn.Linear(hidden_size, n_actions)\n",
    "        self.logstd_layer = nn.Linear(hidden_size, n_actions)\n",
    "        '''\n",
    "        self.shared_net = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(400, 300), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "        self.mean_layer = nn.Linear(300, n_actions)\n",
    "        self.logstd_layer = nn.Linear(300, n_actions)\n",
    "\n",
    "    def forward(self, x: FloatTensor) -> TanhMultivariateNormal:\n",
    "        \"\"\"Forward pass through network. Calculates the action distribution.\n",
    "        Args:\n",
    "            x: input to network\n",
    "        Returns:\n",
    "            action distribution\n",
    "        \"\"\"\n",
    "        # DEBUG\n",
    "        #print(f\"x.device = {x.device}\")\n",
    "        #print(f\"next(self.parameters()).is_cuda = {next(self.parameters()).is_cuda}\")\n",
    "        \n",
    "        x = self.shared_net(x.float())\n",
    "        batch_mean = self.mean_layer(x)\n",
    "        logstd = torch.clamp(self.logstd_layer(x), -20, 2)\n",
    "        batch_scale_tril = torch.diag_embed(torch.exp(logstd))\n",
    "        output = TanhMultivariateNormal(action_bias=self.action_bias, \n",
    "                                        action_scale=self.action_scale, \n",
    "                                        loc=batch_mean, \n",
    "                                        scale_tril=batch_scale_tril,)\n",
    "        return output\n",
    "\n",
    "    def get_action(self, x: FloatTensor) -> Tensor:\n",
    "        \"\"\"Get the action greedily (without sampling)\n",
    "        Args:\n",
    "            x: input to network\n",
    "        Returns:\n",
    "            mean action\n",
    "        \"\"\"\n",
    "        x = self.shared_net(x.float())\n",
    "        batch_mean = self.mean_layer(x)\n",
    "        return self.action_scale * torch.tanh(batch_mean) + self.action_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dafea3-06b1-4f44-9428-2d75ebe06af4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff6c0de-6506-4a8e-b205-189f818ae4f8",
   "metadata": {},
   "source": [
    "Environment and *LightningModule*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394bc1a0-8154-410a-885a-3dba731d7587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/gym/utils/env_checker.py:144: UserWarning: \u001b[33mWARN: Agent's minimum observation space value is -infinity. This is probably too low.\u001b[0m\n",
      "  logger.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/gym/utils/env_checker.py:148: UserWarning: \u001b[33mWARN: Agent's maxmimum observation space value is infinity. This is probably too high\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# train_env = gym.make(\"HalfCheetah-v4\", render_mode = \"rgb_array\") # gym v0.26.2\n",
    "train_env = gym.make(\"HalfCheetah-v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfeac851-5b98-4b01-94f7-96a7f496df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DDPGS(env = train_env,\n",
    "              sync_rate = 20,\n",
    "              gamma = 0.98,\n",
    "              warm_start_size = 5000, #5000\n",
    "              min_episode_reward = 0,\n",
    "              seed = 101,\n",
    "              n_steps = 10,\n",
    "              policy_learning_rate = 1e-4,\n",
    "              q_learning_rate = 1e-4,\n",
    "              target_alpha = 5e-3,\n",
    "              batch_size = 128,\n",
    "              replay_size = 1000000,\n",
    "              avg_reward_len = 100,\n",
    "              batches_per_epoch = 10000,\n",
    "              num_workers = 6,\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe50bec-b4c2-4f47-abe5-f9771b928599",
   "metadata": {},
   "source": [
    "Instantiate trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6198e26c-d9cc-4be9-b079-38651276407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# save checkpoints based on avg_reward\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=1, \n",
    "                                      monitor=\"avg_reward\", \n",
    "                                      mode=\"max\", \n",
    "                                      verbose=True)\n",
    "seed_everything(123)\n",
    "trainer = Trainer(accelerator=\"gpu\", \n",
    "                  max_steps=500000,  # 100000, 1000000\n",
    "                  callbacks = checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03572468-8786-48b9-838d-fb844e47dc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    ##########################################\n",
    "    ### TRAINER TEST (NO MODEL CHECKPOINT) ###\n",
    "    ##########################################\n",
    "'''\n",
    "seed_everything(123)\n",
    "trainer = Trainer(accelerator=\"gpu\", \n",
    "                  max_steps=5000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3270bf-2500-4f6c-b6e5-0c6d3229399d",
   "metadata": {},
   "source": [
    "Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4328c8c1-ff00-4c3e-abc0-a50c7f55e311",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f1b29ca2e50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "083b126f-6711-4cb5-89ec-056b380c5f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | policy       | ContinuousMLP | 73.5 K\n",
      "1 | q_net        | MLP           | 72.2 K\n",
      "2 | target_q_net | MLP           | 72.2 K\n",
      "-----------------------------------------------\n",
      "217 K     Trainable params\n",
      "0         Non-trainable params\n",
      "217 K     Total params\n",
      "0.871     Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.9/dist-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n",
      "/usr/local/lib/python3.9/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/usr/local/lib/python3.9/dist-packages/keras/utils/image_utils.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': pil_image.NEAREST,\n",
      "/usr/local/lib/python3.9/dist-packages/keras/utils/image_utils.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': pil_image.BILINEAR,\n",
      "/usr/local/lib/python3.9/dist-packages/keras/utils/image_utils.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': pil_image.BICUBIC,\n",
      "/usr/local/lib/python3.9/dist-packages/keras/utils/image_utils.py:39: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  'hamming': pil_image.HAMMING,\n",
      "/usr/local/lib/python3.9/dist-packages/keras/utils/image_utils.py:40: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  'box': pil_image.BOX,\n",
      "/usr/local/lib/python3.9/dist-packages/keras/utils/image_utils.py:41: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  'lanczos': pil_image.LANCZOS,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> ENTERING train_dataloader()\n",
      "==> ENTERING _dataloader()\n",
      "==> ENTERING populate()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/Lightning/RL_lightning_bolts_template/pl_ddpgs.py:138: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  states = torch.tensor(states, device=device)\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff6dcd915fa4e43b5692fc1726833b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/Lightning/RL_lightning_bolts_template/pl_bolts_replay_buffers.py:96: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.array(dones, dtype=np.bool),\n",
      "/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py:148: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.as_tensor(batch)\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:234: UserWarning: You called `self.log('total_reward', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:234: UserWarning: You called `self.log('episodes', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:234: UserWarning: You called `self.log('episode_steps', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> STARTING train_batch()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n",
      "==> STARTING training_step()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=5000` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e8078f6-1f6c-46c3-85ad-c5cd9c5c9837",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./pl_ddpg_gym0240_2306272310\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e11359-477d-4ae4-b169-fbfa4778e280",
   "metadata": {},
   "source": [
    "## B) Test trained model\n",
    "\n",
    "To load a model from a checkpoint:\n",
    "\n",
    "https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81d9c645-9509-4079-8458-4f1230ed36b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import wrappers\n",
    "from pyvirtualdisplay import Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08053db5-8a67-4c4b-b06c-ffc5645144c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/gym/utils/env_checker.py:144: UserWarning: \u001b[33mWARN: Agent's minimum observation space value is -infinity. This is probably too low.\u001b[0m\n",
      "  logger.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/gym/utils/env_checker.py:148: UserWarning: \u001b[33mWARN: Agent's maxmimum observation space value is infinity. This is probably too high\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last saved model\n",
    "# test_model = DDPGS(env = gym.make(\"HalfCheetah-v4\", render_mode = \"rgb_array\"))\n",
    "test_model = DDPGS(env = gym.make(\"HalfCheetah-v4\"))\n",
    "test_model.load_state_dict(torch.load(\"./pl_ddpg_gym0240_2306272205\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ae5bf24-49c7-474a-9757-50f48ea98b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4053c7ee-b674-4003-92a4-07a501a3e170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DDPGS(\n",
       "  (policy): ContinuousMLP(\n",
       "    (shared_net): Sequential(\n",
       "      (0): Linear(in_features=17, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (mean_layer): Linear(in_features=256, out_features=6, bias=True)\n",
       "    (logstd_layer): Linear(in_features=256, out_features=6, bias=True)\n",
       "  )\n",
       "  (q_net): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=23, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (target_q_net): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=23, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best model from Trainer checkpoint\n",
    "#test_model = DDPGS(env = gym.make(\"HalfCheetah-v4\", render_mode = \"rgb_array\"))\n",
    "test_model = DDPGS.load_from_checkpoint(\"./lightning_logs/version_7/checkpoints/epoch=24-step=500000.ckpt\")\n",
    "\n",
    "# disable randomness, dropout, etc...\n",
    "test_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f885625-f6a5-45f5-a4a9-d1db3572a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make virtual display\n",
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()\n",
    "\n",
    "# Trigger for wrapper.RecordVideo() object\n",
    "def epsd_trigger(episode_id: int) -> bool:\n",
    "    '''\n",
    "        Records all episodes\n",
    "    '''\n",
    "    if episode_id < 10:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d921b59c-07dc-4b19-9763-c81b00aeaddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "532aac88-968d-4e30-a1b8-e509a4930b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/gym/utils/env_checker.py:144: UserWarning: \u001b[33mWARN: Agent's minimum observation space value is -infinity. This is probably too low.\u001b[0m\n",
      "  logger.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/gym/utils/env_checker.py:148: UserWarning: \u001b[33mWARN: Agent's maxmimum observation space value is infinity. This is probably too high\u001b[0m\n",
      "  logger.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/gym/wrappers/record_video.py:75: UserWarning: \u001b[33mWARN: Overwriting existing videos at /notebooks/Lightning/vids folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Test env\n",
    "#env = gym.make(\"HalfCheetah-v4\", render_mode = \"rgb_array\")\n",
    "env = gym.make(\"HalfCheetah-v4\")\n",
    "env = wrappers.RecordVideo(env = env, \n",
    "                           video_folder=\"vids/\",\n",
    "                           name_prefix=\"DDPGs_pl_gym0240_100kSteps_TweedNets_2306272310\",\n",
    "                           episode_trigger = epsd_trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "585902db-bf33-4107-b0e0-31b1da4f53b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0,\tSteps: 1000,\tscore: 1745.4410614420235\n",
      "Episode: 1,\tSteps: 1000,\tscore: 1826.341708302102\n",
      "Episode: 2,\tSteps: 1000,\tscore: 1722.5220128503026\n"
     ]
    }
   ],
   "source": [
    "# Main loop\n",
    "for episode in range(3):\n",
    "    \n",
    "    # Init. env. and counters\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    total_reward = 0\n",
    "    n_prds = 0\n",
    "    done = False\n",
    "    trunc = False\n",
    "    \n",
    "    # Episodic loop\n",
    "    while not done and step<5001:\n",
    "        \n",
    "        # Render\n",
    "        env.render()\n",
    "        \n",
    "        # Get action\n",
    "        with torch.no_grad():\n",
    "            state_ = torch.FloatTensor(np.array(state)).to(test_model.device)\n",
    "            # Get actions and UPolicy output\n",
    "            action_ = test_model.policy.get_action(state_)\n",
    "            # Get np arrays\n",
    "            action = action_.cpu().detach().numpy()\n",
    "        \n",
    "        # Environment step\n",
    "        state_next, reward, done, info = env.step(action)\n",
    "        # Update tot. score\n",
    "        total_reward += reward\n",
    "        # Update step\n",
    "        step += 1\n",
    "        # Update state\n",
    "        state = state_next\n",
    "        # End of episode\n",
    "        if done:\n",
    "            print(f\"Episode: {episode},\\tSteps: {step},\\tscore: {total_reward}\")\n",
    "            break\n",
    "\n",
    "# Close environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e1ba1a-cb1f-403d-b8e0-6a92b4644f6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Testing the Algo (Version 1 - 2306221408)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578e46c8-5a7f-43d4-98fc-b7aad488fc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch import Tensor, optim, FloatTensor, Tensor, nn\n",
    "from torch.distributions import Categorical, Normal, MultivariateNormal\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b562bb23-5b18-4baa-9cc6-5529245368b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RL_lightning_bolts_template.pl_ddpgs import DDPGS\n",
    "from RL_lightning_bolts_template.pl_bolts_nets import TanhMultivariateNormal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a225d-80b0-4b19-a706-ca58b28a04e0",
   "metadata": {},
   "source": [
    "## A) Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea61e54-1003-471d-9a23-4aec449a6b05",
   "metadata": {},
   "source": [
    "### Critic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "876011f4-0ec7-46c2-b007-01e27fc01abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Simple MLP network.\"\"\"\n",
    "\n",
    "    def __init__(self, input_shape: Tuple[int], n_actions: int, hidden_size: int = 128):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_shape: observation shape of the environment\n",
    "            n_actions: number of discrete actions available in the environment\n",
    "            hidden_size: size of hidden layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        '''\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_actions),\n",
    "        )\n",
    "        '''\n",
    "        # AJZ, 23/06/25\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(400, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(300, n_actions),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_x):\n",
    "        \"\"\"Forward pass through network.\n",
    "        Args:\n",
    "            x: input to network\n",
    "        Returns:\n",
    "            output of network\n",
    "        \"\"\"\n",
    "        return self.net(input_x.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933265a7-718a-4ef7-bf39-b6da6ac0b502",
   "metadata": {},
   "source": [
    "### Actor net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbce0c49-c42e-494b-942e-104b55adfb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousMLP(nn.Module):\n",
    "    \"\"\"MLP network that outputs continuous value via Gaussian distribution.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: Tuple[int],\n",
    "        n_actions: int,\n",
    "        hidden_size: int = 128,\n",
    "        action_bias: int = 0,\n",
    "        action_scale: int = 1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_shape: observation shape of the environment\n",
    "            n_actions: dimension of actions in the environment\n",
    "            hidden_size: size of hidden layers\n",
    "            action_bias: the center of the action space\n",
    "            action_scale: the scale of the action space\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.action_bias = action_bias\n",
    "        self.action_scale = action_scale\n",
    "        '''\n",
    "        self.shared_net = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], hidden_size), nn.ReLU(), nn.Linear(hidden_size, hidden_size), nn.ReLU()\n",
    "        )\n",
    "        self.mean_layer = nn.Linear(hidden_size, n_actions)\n",
    "        self.logstd_layer = nn.Linear(hidden_size, n_actions)\n",
    "        '''\n",
    "        self.shared_net = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(400, 300), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "        self.mean_layer = nn.Linear(300, n_actions)\n",
    "        self.logstd_layer = nn.Linear(300, n_actions)\n",
    "\n",
    "    def forward(self, x: FloatTensor) -> TanhMultivariateNormal:\n",
    "        \"\"\"Forward pass through network. Calculates the action distribution.\n",
    "        Args:\n",
    "            x: input to network\n",
    "        Returns:\n",
    "            action distribution\n",
    "        \"\"\"\n",
    "        # DEBUG\n",
    "        #print(f\"x.device = {x.device}\")\n",
    "        #print(f\"next(self.parameters()).is_cuda = {next(self.parameters()).is_cuda}\")\n",
    "        \n",
    "        x = self.shared_net(x.float())\n",
    "        batch_mean = self.mean_layer(x)\n",
    "        logstd = torch.clamp(self.logstd_layer(x), -20, 2)\n",
    "        batch_scale_tril = torch.diag_embed(torch.exp(logstd))\n",
    "        output = TanhMultivariateNormal(action_bias=self.action_bias, \n",
    "                                        action_scale=self.action_scale, \n",
    "                                        loc=batch_mean, \n",
    "                                        scale_tril=batch_scale_tril,)\n",
    "        return output\n",
    "\n",
    "    def get_action(self, x: FloatTensor) -> Tensor:\n",
    "        \"\"\"Get the action greedily (without sampling)\n",
    "        Args:\n",
    "            x: input to network\n",
    "        Returns:\n",
    "            mean action\n",
    "        \"\"\"\n",
    "        x = self.shared_net(x.float())\n",
    "        batch_mean = self.mean_layer(x)\n",
    "        return self.action_scale * torch.tanh(batch_mean) + self.action_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d6daa4-b879-473c-8939-048694566fd3",
   "metadata": {},
   "source": [
    "Environment and *LightningModule*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca97333-f318-466b-a615-acae97ca3ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/gym/utils/env_checker.py:144: UserWarning: \u001b[33mWARN: Agent's minimum observation space value is -infinity. This is probably too low.\u001b[0m\n",
      "  logger.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/gym/utils/env_checker.py:148: UserWarning: \u001b[33mWARN: Agent's maxmimum observation space value is infinity. This is probably too high\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# train_env = gym.make(\"HalfCheetah-v4\", render_mode = \"rgb_array\") # gym v0.26.2\n",
    "train_env = gym.make(\"HalfCheetah-v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6efbcb50-a1b7-4f06-8d79-9a83e579049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DDPGS(env = train_env,\n",
    "              sync_rate = 20,\n",
    "              gamma = 0.98,\n",
    "              warm_start_size = 10000, #5000\n",
    "              min_episode_reward = 0,\n",
    "              seed = 101,\n",
    "              n_steps = 10,\n",
    "              policy_learning_rate = 1e-4,\n",
    "              q_learning_rate = 1e-4,\n",
    "              target_alpha = 5e-3,\n",
    "              batch_size = 100,\n",
    "              replay_size = 200000,\n",
    "              avg_reward_len = 100,\n",
    "              batches_per_epoch = 10000,\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58eab94-5241-497a-bd8f-bbe2b7ad7528",
   "metadata": {},
   "source": [
    "Instantiate trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd6d19f-4a2f-4e75-b3f8-bea26e22c8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# save checkpoints based on avg_reward\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=1, \n",
    "                                      monitor=\"avg_reward\", \n",
    "                                      mode=\"max\", \n",
    "                                      verbose=True)\n",
    "seed_everything(123)\n",
    "trainer = Trainer(accelerator=\"gpu\", \n",
    "                  max_steps=100000,  # 100000, 1000000\n",
    "                  callbacks = checkpoint_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f85aeb1-af83-4ea4-b712-4026b829c076",
   "metadata": {},
   "source": [
    "Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1952fdb-9788-4586-9726-37e2d6010c53",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f1b29ca2e50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73a89432-3120-4eed-9f70-cc602fae74d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | policy       | ContinuousMLP | 131 K \n",
      "1 | q_net        | MLP           | 130 K \n",
      "2 | target_q_net | MLP           | 130 K \n",
      "-----------------------------------------------\n",
      "391 K     Trainable params\n",
      "0         Non-trainable params\n",
      "391 K     Total params\n",
      "1.566     Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.9/dist-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n",
      "/usr/local/lib/python3.9/dist-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/usr/local/lib/python3.9/dist-packages/keras/utils/image_utils.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': pil_image.NEAREST,\n",
      "/usr/local/lib/python3.9/dist-packages/keras/utils/image_utils.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': pil_image.BILINEAR,\n",
      "/usr/local/lib/python3.9/dist-packages/keras/utils/image_utils.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': pil_image.BICUBIC,\n",
      "/usr/local/lib/python3.9/dist-packages/keras/utils/image_utils.py:39: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  'hamming': pil_image.HAMMING,\n",
      "/usr/local/lib/python3.9/dist-packages/keras/utils/image_utils.py:40: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  'box': pil_image.BOX,\n",
      "/usr/local/lib/python3.9/dist-packages/keras/utils/image_utils.py:41: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  'lanczos': pil_image.LANCZOS,\n",
      "/notebooks/Lightning/RL_lightning_bolts_template/pl_ddpgs.py:138: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  states = torch.tensor(states, device=device)\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4846557dd3314f38aa059397fb137afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/Lightning/RL_lightning_bolts_template/pl_bolts_replay_buffers.py:96: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.array(dones, dtype=np.bool),\n",
      "/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py:148: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.as_tensor(batch)\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:234: UserWarning: You called `self.log('total_reward', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:234: UserWarning: You called `self.log('episodes', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:234: UserWarning: You called `self.log('episode_steps', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "Epoch 0, global step 20000: 'avg_reward' reached -30.47791 (best -30.47791), saving model to '/notebooks/Lightning/lightning_logs/version_5/checkpoints/epoch=0-step=20000.ckpt' as top 1\n",
      "Epoch 1, global step 40000: 'avg_reward' reached -26.98513 (best -26.98513), saving model to '/notebooks/Lightning/lightning_logs/version_5/checkpoints/epoch=1-step=40000.ckpt' as top 1\n",
      "Epoch 2, global step 60000: 'avg_reward' reached -12.04049 (best -12.04049), saving model to '/notebooks/Lightning/lightning_logs/version_5/checkpoints/epoch=2-step=60000.ckpt' as top 1\n",
      "Epoch 3, global step 80000: 'avg_reward' reached 21.86908 (best 21.86908), saving model to '/notebooks/Lightning/lightning_logs/version_5/checkpoints/epoch=3-step=80000.ckpt' as top 1\n",
      "Epoch 4, global step 100000: 'avg_reward' reached 78.26254 (best 78.26254), saving model to '/notebooks/Lightning/lightning_logs/version_5/checkpoints/epoch=4-step=100000.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_steps=100000` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97cf1cf0-fb78-4f3c-b8fc-f5abce11bbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./pl_ddpg_gym0240_2306251635\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10556c85-9fff-4a30-b947-094752daf4a6",
   "metadata": {},
   "source": [
    "## B) Test trained model\n",
    "\n",
    "To load a model from a checkpoint:\n",
    "\n",
    "https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21207f1a-e73b-40a0-af69-54f17fa35958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import wrappers\n",
    "from pyvirtualdisplay import Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b3aa3d-b606-4e0c-a687-5ceb00cd9d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/gym/utils/env_checker.py:144: UserWarning: \u001b[33mWARN: Agent's minimum observation space value is -infinity. This is probably too low.\u001b[0m\n",
      "  logger.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/gym/utils/env_checker.py:148: UserWarning: \u001b[33mWARN: Agent's maxmimum observation space value is infinity. This is probably too high\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last saved model\n",
    "# test_model = DDPGS(env = gym.make(\"HalfCheetah-v4\", render_mode = \"rgb_array\"))\n",
    "test_model = DDPGS(env = gym.make(\"HalfCheetah-v4\"))\n",
    "test_model.load_state_dict(torch.load(\"./pl_ddpg_gym0240_2306251635\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bdb7ab2-5b4c-4a91-865b-b4b2ec890063",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db58e0d6-46d4-48a1-91d7-b6086e96b7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DDPGS(\n",
       "  (policy): ContinuousMLP(\n",
       "    (shared_net): Sequential(\n",
       "      (0): Linear(in_features=17, out_features=400, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=400, out_features=300, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (mean_layer): Linear(in_features=300, out_features=6, bias=True)\n",
       "    (logstd_layer): Linear(in_features=300, out_features=6, bias=True)\n",
       "  )\n",
       "  (q_net): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=23, out_features=400, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=400, out_features=300, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=300, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (target_q_net): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=23, out_features=400, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=400, out_features=300, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=300, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best model from Trainer checkpoint\n",
    "#test_model = DDPGS(env = gym.make(\"HalfCheetah-v4\", render_mode = \"rgb_array\"))\n",
    "test_model = DDPGS.load_from_checkpoint(\"./lightning_logs/version_4/checkpoints/epoch=4-step=100000.ckpt\")\n",
    "\n",
    "# disable randomness, dropout, etc...\n",
    "test_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6d11a0f-a317-42e5-b75d-6b28b9aa2f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make virtual display\n",
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()\n",
    "\n",
    "# Trigger for wrapper.RecordVideo() object\n",
    "def epsd_trigger(episode_id: int) -> bool:\n",
    "    '''\n",
    "        Records all episodes\n",
    "    '''\n",
    "    if episode_id < 10:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff85dcb-81a2-48ec-956d-47b1a4b94647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3524d1d5-73a9-4f1a-b702-638891d07bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/gym/utils/env_checker.py:144: UserWarning: \u001b[33mWARN: Agent's minimum observation space value is -infinity. This is probably too low.\u001b[0m\n",
      "  logger.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/gym/utils/env_checker.py:148: UserWarning: \u001b[33mWARN: Agent's maxmimum observation space value is infinity. This is probably too high\u001b[0m\n",
      "  logger.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/gym/wrappers/record_video.py:75: UserWarning: \u001b[33mWARN: Overwriting existing videos at /notebooks/Lightning/vids folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Test env\n",
    "#env = gym.make(\"HalfCheetah-v4\", render_mode = \"rgb_array\")\n",
    "env = gym.make(\"HalfCheetah-v4\")\n",
    "env = wrappers.RecordVideo(env = env, \n",
    "                           video_folder=\"vids/\",\n",
    "                           name_prefix=\"DDPGs_pl_gym0240_100kSteps_Corrected_2306261653\",\n",
    "                           episode_trigger = epsd_trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7108798-f330-456c-b7a9-dfa50b262809",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0,\tSteps: 1000,\tscore: -75.82073089709843\n",
      "Episode: 1,\tSteps: 1000,\tscore: -50.94959431896886\n"
     ]
    }
   ],
   "source": [
    "for episode in range(2):\n",
    "    #state, _ = env.reset()\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done and step<5001:\n",
    "        step += 1\n",
    "        env.render()\n",
    "        # Get action\n",
    "        with torch.no_grad():\n",
    "            # Convert to torch tensors\n",
    "            state_ = torch.FloatTensor(np.array(state)).to(test_model.device)\n",
    "            # Get actions and UPolicy output\n",
    "            #action_ = actor(control, state_, t_)\n",
    "            #action_ = test_model(state_)\n",
    "            action_ = test_model.policy.get_action(state_)\n",
    "            # Get np arrays\n",
    "            action = action_.cpu().detach().numpy()\n",
    "        \n",
    "        #observation, reward, done, trunc, info = env.step(action)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            print(\"Episode: {0},\\tSteps: {1},\\tscore: {2}\"\n",
    "                  .format(episode, step, total_reward)\n",
    "            )\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01a4c62b-5d69-4e2c-867c-25d5ebfa812f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0,\tSteps: 1000,\tscore: 746.109141219302\n",
      "Episode: 1,\tSteps: 1000,\tscore: 751.0345682717375\n"
     ]
    }
   ],
   "source": [
    "# Main loop\n",
    "for episode in range(2):\n",
    "    \n",
    "    # Init. env. and counters\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    total_reward = 0\n",
    "    n_prds = 0\n",
    "    done = False\n",
    "    trunc = False\n",
    "    '''\n",
    "    # Initial ampl omega and phi\n",
    "    with th.no_grad():\n",
    "        state_ = th.FloatTensor(np.array(state)).to(test_control.device)\n",
    "        ampl_, omega_, phi_ = test_control(state_)\n",
    "    '''\n",
    "    \n",
    "    # Episodic loop\n",
    "    while not done and step<5001:\n",
    "        \n",
    "        # Render\n",
    "        env.render()\n",
    "        '''\n",
    "        t = float(step-n_prds*n_delay_steps)\n",
    "        '''\n",
    "        \n",
    "        # Get action\n",
    "        with torch.no_grad():\n",
    "            '''\n",
    "            # Convert to torch tensors\n",
    "            t_ = th.FloatTensor(np.array(t)).to(test_control.device)\n",
    "            '''\n",
    "            state_ = torch.FloatTensor(np.array(state)).to(test_model.device)\n",
    "            # Get actions and UPolicy output\n",
    "            action_ = test_model.policy.get_action(state_)\n",
    "            # Get np arrays\n",
    "            action = action_.cpu().detach().numpy()\n",
    "        \n",
    "        # Environment step\n",
    "        state_next, reward, done, info = env.step(action)\n",
    "        # Update tot. score\n",
    "        total_reward += reward\n",
    "        # Update step\n",
    "        step += 1\n",
    "        # Update state\n",
    "        state = state_next\n",
    "        '''\n",
    "        # End of period updates\n",
    "        if step % n_delay_steps == 0:\n",
    "            \n",
    "            # Update no. of periods\n",
    "            n_prds += 1\n",
    "            \n",
    "            # Update amplitude, frequ. and phase\n",
    "            with th.no_grad():\n",
    "                state_ = th.FloatTensor(np.array(state)).to(test_control.device)\n",
    "                ampl_, omega_, phi_ = test_control(state_)\n",
    "        '''\n",
    "        \n",
    "        # End of episode\n",
    "        if done:\n",
    "            print(f\"Episode: {episode},\\tSteps: {step},\\tscore: {total_reward}\")\n",
    "            break\n",
    "\n",
    "# Close environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088e0494-aaa1-4b68-baff-def52cb45eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40497069-d82c-46c8-b2d7-5d7febab2cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8191e902-8d32-4b97-8d36-57de7e3d3bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ce887-a741-4d07-b072-a8c266578435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfc60e34-d81c-4219-aa5f-922b1ca416ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Testing the Algo (Version 0 - 2306220120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4024b2-e53f-4eda-b47c-b8b97e8fbf8f",
   "metadata": {},
   "source": [
    "## A) Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c6907e-c5da-4069-a3bf-8c926790fa83",
   "metadata": {},
   "source": [
    "Environment and *LightningModule*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e50e729c-2d88-4eb5-9bee-3563ebb0476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = gym.make(\"HalfCheetah-v4\", render_mode = \"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e92e6a64-ba0f-4cf6-8694-85d698f3aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DDPGS(env = train_env,\n",
    "    sync_rate = 10,\n",
    "    gamma = 0.98,\n",
    "    warm_start_size = 5000,\n",
    "    min_episode_reward = -21,\n",
    "    seed = 101,\n",
    "    n_steps = 10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a9fad-8b88-4507-8bf7-259efe3ef15b",
   "metadata": {},
   "source": [
    "Instantiate trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "590416ee-845d-494e-99c6-256a4470cca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 101\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# save checkpoints based on avg_reward\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=1, \n",
    "                                      monitor=\"avg_reward\", \n",
    "                                      mode=\"max\", \n",
    "                                      verbose=True)\n",
    "seed_everything(101)\n",
    "trainer = Trainer(accelerator=\"gpu\", \n",
    "                  max_steps=100000,  \n",
    "                  callbacks = checkpoint_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c63e91-0726-4fa0-9f41-acd9d1de2187",
   "metadata": {},
   "source": [
    "Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deb41d16-5770-48be-8f7c-6982c7b6e2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type | Params\n",
      "--------------------------------------\n",
      "0 | policy       | MLP  | 3.1 K \n",
      "1 | q_net        | MLP  | 3.2 K \n",
      "2 | target_q_net | MLP  | 3.2 K \n",
      "--------------------------------------\n",
      "9.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.5 K     Total params\n",
      "0.038     Total estimated model params size (MB)\n",
      "/tmp/ipykernel_36228/3927047624.py:110: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  states = torch.tensor(states, device=device)\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0d7443f8144084b9e8bf6d71d7f1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:234: UserWarning: You called `self.log('total_reward', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:234: UserWarning: You called `self.log('episodes', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:234: UserWarning: You called `self.log('episode_steps', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "Epoch 0, global step 20000: 'avg_reward' reached -21.00000 (best -21.00000), saving model to '/notebooks/Deep_Forecasting/lightning_logs/version_8/checkpoints/epoch=0-step=20000.ckpt' as top 1\n",
      "Epoch 1, global step 40000: 'avg_reward' was not in top 1\n",
      "Epoch 2, global step 60000: 'avg_reward' was not in top 1\n",
      "Epoch 3, global step 80000: 'avg_reward' was not in top 1\n",
      "Epoch 4, global step 100000: 'avg_reward' was not in top 1\n",
      "`Trainer.fit` stopped: `max_steps=100000` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "773893a8-5eb1-428d-8fd5-8f87b67db55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./ddpg_lightning_gym0262_2306220130\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b733742-12d1-41ff-b926-0ade71293af2",
   "metadata": {},
   "source": [
    "## B) Test trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95768525-1879-40b0-850f-cd4a1a891e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import wrappers\n",
    "from pyvirtualdisplay import Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95ec83ec-e15f-4e12-9d45-b0b12335082c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = DDPGS(env = gym.make(\"HalfCheetah-v4\", render_mode = \"rgb_array\"))\n",
    "test_model.load_state_dict(torch.load(\"./ddpg_lightning_gym0262_2306220130\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df7abd4c-61df-47cc-bedb-5b357c0ce2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make virtual display\n",
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()\n",
    "\n",
    "# Trigger for wrapper.RecordVideo() object\n",
    "def epsd_trigger(episode_id: int) -> bool:\n",
    "    '''\n",
    "        Records all episodes\n",
    "    '''\n",
    "    if episode_id < 10:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Test env\n",
    "env = gym.make(\"HalfCheetah-v4\", render_mode = \"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "892d2db4-fe81-428f-b831-5084d81dff34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7f5176972d00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a03edaf2-8be0-4599-8b64-e862bb3f783c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/gym/wrappers/record_video.py:75: UserWarning: \u001b[33mWARN: Overwriting existing videos at /notebooks/Deep_Forecasting/vids folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = wrappers.RecordVideo(env = env, \n",
    "                           video_folder=\"vids/\",\n",
    "                           name_prefix=\"DDPGs_pl_gym0262_2306220135\",\n",
    "                           episode_trigger = epsd_trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "445c5bfa-60d0-41c3-b2d8-a7f96ec7e0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /notebooks/Deep_Forecasting/vids/DDPGs_pl_gym0262_2306220135-episode-0.mp4.\n",
      "Moviepy - Writing video /notebooks/Deep_Forecasting/vids/DDPGs_pl_gym0262_2306220135-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /notebooks/Deep_Forecasting/vids/DDPGs_pl_gym0262_2306220135-episode-0.mp4\n",
      "Moviepy - Building video /notebooks/Deep_Forecasting/vids/DDPGs_pl_gym0262_2306220135-episode-1.mp4.\n",
      "Moviepy - Writing video /notebooks/Deep_Forecasting/vids/DDPGs_pl_gym0262_2306220135-episode-1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /notebooks/Deep_Forecasting/vids/DDPGs_pl_gym0262_2306220135-episode-1.mp4\n",
      "Moviepy - Building video /notebooks/Deep_Forecasting/vids/DDPGs_pl_gym0262_2306220135-episode-2.mp4.\n",
      "Moviepy - Writing video /notebooks/Deep_Forecasting/vids/DDPGs_pl_gym0262_2306220135-episode-2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /notebooks/Deep_Forecasting/vids/DDPGs_pl_gym0262_2306220135-episode-2.mp4\n"
     ]
    }
   ],
   "source": [
    "for episode in range(3):\n",
    "    state, _ = env.reset()\n",
    "    step = 0\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done and step<5001:\n",
    "        step += 1\n",
    "        #env.render()\n",
    "        # Get action\n",
    "        with torch.no_grad():\n",
    "            # Convert to torch tensors\n",
    "            state_ = torch.FloatTensor(np.array(state)).to(test_model.device)\n",
    "            # Get actions and UPolicy output\n",
    "            #action_ = actor(control, state_, t_)\n",
    "            action_ = test_model(state_)\n",
    "            # Get np arrays\n",
    "            action = action_.cpu().detach().numpy()\n",
    "        \n",
    "        observation, reward, done, trunc, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            print(\"Episode: {0},\\tSteps: {1},\\tscore: {2}\"\n",
    "                  .format(episode, step, total_reward)\n",
    "            )\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850eab4-6e41-4802-a283-be42b2b65a5a",
   "metadata": {},
   "source": [
    "**First version conclusion (23/06/22 - 01:35):** Some hyperparameter tuning is needed. We're on the right track though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714edd36-9c85-4dab-a124-5c199c04af21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
